{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Analysis of Titanic Survival with Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will analyze the open dataset with data on the passengers aboard the Titanic. The main purpose is to analyze, clean and transform the data to answer the following question: \n",
    "\n",
    "> What categories of passengers were most likely to survive the Titanic disaster?\n",
    "\n",
    "The data file `train.csv`, renamed to `titanic_data.csv` here, can be downloaded from Kaggle [here](https://www.kaggle.com/c/titanic/data). The definition of all variables can be found on the same Kaggle page, in the Data Dictionary section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 01.**\n",
    "* We will conduct a detailed analysis to identify what categories of passengers were most likely to survive the Titanic disaster.\n",
    "* We will also learn about the logic of the analysis.\n",
    "\n",
    "**Section 02.**\n",
    "* For all the attributes used for the analysis in the previous section, we will see why and how we used them.\n",
    "\n",
    "**Section 03.**\n",
    "* There were missing values that were not taken into consideration previously. They could have impacted our analysis. We will see how our analysis has changed after dropping the rows with missing values in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data file into a DataFrame\n",
    "df = pd.read_csv(\"titanic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# print(df)\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Check the data types of all columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "        PassengerId    Survived      Pclass                     Name   Sex  \\\n",
      "count    891.000000  891.000000  891.000000                      891   891   \n",
      "unique          NaN         NaN         NaN                      891     2   \n",
      "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
      "freq            NaN         NaN         NaN                        1   577   \n",
      "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
      "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
      "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
      "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
      "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
      "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
      "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
      "\n",
      "               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
      "count   714.000000  891.000000  891.000000     891  891.000000      204   \n",
      "unique         NaN         NaN         NaN     681         NaN      147   \n",
      "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
      "freq           NaN         NaN         NaN       7         NaN        4   \n",
      "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
      "std      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
      "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
      "25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
      "50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
      "75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
      "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
      "\n",
      "       Embarked  \n",
      "count       889  \n",
      "unique        3  \n",
      "top           S  \n",
      "freq        644  \n",
      "mean        NaN  \n",
      "std         NaN  \n",
      "min         NaN  \n",
      "25%         NaN  \n",
      "50%         NaN  \n",
      "75%         NaN  \n",
      "max         NaN  \n"
     ]
    }
   ],
   "source": [
    "## Show descriptive statistics\n",
    "print(df.describe())\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Ticket Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data), `Pclass` refers to ticket class with 1st being the upper class and 3rd the lower class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    216\n",
      "2    184\n",
      "3    491\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"Pclass\")[\"Survived\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower class, 3rd class ticket holders, was the most likely to survive the Titanic disaster. It is almost more than double of the next group most likely to survive - 1st class. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sex` is binary - only `male` and `female`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "female    314\n",
      "male      577\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"Sex\")[\"Survived\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Male passengers are more likely to survive the disaster, almost twice as much as female passengers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age will be grouped according to the different age groups set by [Statistics Canada](https://www.statcan.gc.ca/en/concepts/definitions/previous/age1a) but with the adult group further divided into young and middle-aged adult groups. See the groupings below.\n",
    "\n",
    "- Children (00-14 years)\n",
    "- Youth (15-24 years)\n",
    "- Young Adults (25-40 years)\n",
    "- Middle-aged Adults (41-64 years)\n",
    "- Seniors (65 years and over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest passenger: 80.0 years old\n",
      "Youngest passenger: 0.42 years old\n"
     ]
    }
   ],
   "source": [
    "print(\"Oldest passenger:\", df[\"Age\"].max(), \"years old\")\n",
    "print(\"Youngest passenger:\", df[\"Age\"].min(), \"years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age Groups\n",
       "Children               83\n",
       "Youth                 218\n",
       "Young Adults          271\n",
       "Middle-aged Adults    134\n",
       "Seniors                 8\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sort age values to groups of age ranges\n",
    "bins = [0, 15, 25, 41, 65, 100]\n",
    "group_names = [\"Children\", \"Youth\", \"Young Adults\", \"Middle-aged Adults\", \"Seniors\"]\n",
    "df['Age Groups'] = pd.cut(df[\"Age\"], bins, labels=group_names)\n",
    "# print(df[[\"Age Groups\", \"Survived\"]])\n",
    "df.groupby(\"Age Groups\")[\"Survived\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Young adults are most likely to survive, followed by youth, but seniors are the least likely to survive. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticket fares will be grouped into equal intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most expensive fare: $512.3292\n",
      "Least expensive fare: $0.0\n"
     ]
    }
   ],
   "source": [
    "fare_lowest = df[\"Fare\"].max()\n",
    "print(f\"Most expensive fare: ${fare_lowest}\")\n",
    "fare_highest = df[\"Fare\"].min()\n",
    "print(f\"Least expensive fare: ${fare_highest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low       308\n",
      "High      295\n",
      "Medium    288\n",
      "Name: Fare Range, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Discretize variable into equal-sized buckets based on rank or sample quantiles\n",
    "bin_labels_3 = [\"Low\", \"Medium\", \"High\"]\n",
    "q3 = [0, 1/3, 2/3, 1]\n",
    "df[\"Fare Range\"] = pd.qcut(df[\"Fare\"], q=q3, labels=bin_labels_3)\n",
    "# bin_labels_4 = [\"Quartile 1\", \"Quartile 2\", \"Quartile 3\", \"Quartile 4\"]\n",
    "# q4 = [0, 0.25, 0.5, 0.75, 1]\n",
    "# df[\"Fare Range\"] = pd.qcut(df[\"Fare\"], q=q4, labels=bin_labels_4)\n",
    "# bin_labels_6 = [\"Low Low\", \"Low High\", \"Medium Low\", \"Medium High\", \"High Low\", \"High High\"]\n",
    "# q6 = [0, 1/6, 2/6, .5, 4/6, 5/6, 1]\n",
    "# df[\"Fare Range\"] = pd.qcut(df[\"Fare\"], q=q6, labels=bin_labels_6)\n",
    "print(df[\"Fare Range\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those passengers who bought the lowest-tier tickets were most likely to survive. But the difference between ticket tiers does not seem to be striking in terms of survival rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Embarkation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embarked` refers to ports of Embarkation. \n",
    "\n",
    "- C = Cherbourg\n",
    "- Q = Queenstown\n",
    "- S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n",
      "C    168\n",
      "Q     77\n",
      "S    644\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"Embarked\")[\"Survived\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passengers who embarked at Southampton were significantly more likely to survive the disaster but those at Queenstown had the lowest chance of survival. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic of Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will go through all the attributes and eliminate those not relevant to our analysis. Only those that seem to be relevant are selected: \n",
    "\n",
    "- Ticket Class: `Pclass`\n",
    "- Sex: `Sex`\n",
    "- Age: `Age` and `Age Groups`\n",
    "- Fare: `Fare` and `Fare Range`\n",
    "- Embarkation: `Embarked`\n",
    "\n",
    "Analysis is made simpler by analyzing those category one by one. For categorial data (`Pclass`, `Sex` and `Embarked`), we can perform simple analysis by grouping data in thsoe columns and count the `Survived` indicator of 1. However, for those with continuous numeric data (`Age` and `Fare`), we should define ranges and intervals for grouping first. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age Groups',\n",
      "       'Fare Range'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       int64\n",
      "Survived          int64\n",
      "Pclass            int64\n",
      "Name             object\n",
      "Sex              object\n",
      "Age             float64\n",
      "SibSp             int64\n",
      "Parch             int64\n",
      "Ticket           object\n",
      "Fare            float64\n",
      "Cabin            object\n",
      "Embarked         object\n",
      "Age Groups     category\n",
      "Fare Range     category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Check the data types of all columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes used for analysis: \n",
    "\n",
    "```python\n",
    "[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why & How"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age Groups` and `Fare Range` are created from the original attributes `['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']`\n",
    "\n",
    "Why:\n",
    "\n",
    "- `PassengerId` and `Name` are randomly assigned to passengers and therefore not useful in telling the survival rate.\n",
    "- `Survived` is a crucial attribute in knowing whether the passengers survived in the disaster. \n",
    "- `Pclass` might be a factor as it reflects the social status of the passengers.\n",
    "- `Sex` and `Age` are indicators of physical strength and so may affect the survival rate in a life-or-death situation.\n",
    "- `Ticket` and `Cabin` seem to be randomly coded and assigned so it does not give much information about survival rate.\n",
    "- `Fare`, however, is similar to `Pclass` in the sense that it indicates the economic status of the passengers.\n",
    "- `Embarked` can somehow tell the social status of the passengers since people of different social classes live in different areas and they tend to embark at the nearest port to their residential area.\n",
    "\n",
    "How: \n",
    "\n",
    "- `Survived` is binary coded - only 1 and 0 - so we can simply count rows where it is coded as `1` when analyzing different categories.\n",
    "- `Pclass`, `Sex` and `Embarked` are categorial data and so we can just use `groupby()` to classify the data.\n",
    "- `Age` and `Fare` are continuous numeric data and just use `groupby()` to group the values would be useless. Therefore, we should create age groups (`Age Groups`) and divide fare into tiers (`Fare Range`) before counting the data ranges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 03"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop rows with all or any NA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket  \\\n",
      "0          False     False   False  False  False  False  False  False   False   \n",
      "1          False     False   False  False  False  False  False  False   False   \n",
      "2          False     False   False  False  False  False  False  False   False   \n",
      "3          False     False   False  False  False  False  False  False   False   \n",
      "4          False     False   False  False  False  False  False  False   False   \n",
      "..           ...       ...     ...    ...    ...    ...    ...    ...     ...   \n",
      "886        False     False   False  False  False  False  False  False   False   \n",
      "887        False     False   False  False  False  False  False  False   False   \n",
      "888        False     False   False  False  False   True  False  False   False   \n",
      "889        False     False   False  False  False  False  False  False   False   \n",
      "890        False     False   False  False  False  False  False  False   False   \n",
      "\n",
      "      Fare  Cabin  Embarked  Age Groups  Fare Range  \n",
      "0    False   True     False       False       False  \n",
      "1    False  False     False       False       False  \n",
      "2    False   True     False       False       False  \n",
      "3    False  False     False       False       False  \n",
      "4    False   True     False       False       False  \n",
      "..     ...    ...       ...         ...         ...  \n",
      "886  False   True     False       False       False  \n",
      "887  False  False     False       False       False  \n",
      "888  False   True     False        True       False  \n",
      "889  False  False     False       False       False  \n",
      "890  False   True     False       False       False  \n",
      "\n",
      "[891 rows x 14 columns]\n",
      "0       True\n",
      "1      False\n",
      "2       True\n",
      "3      False\n",
      "4       True\n",
      "       ...  \n",
      "886     True\n",
      "887    False\n",
      "888     True\n",
      "889    False\n",
      "890     True\n",
      "Length: 891, dtype: bool\n",
      "   PassengerId  Survived  Pclass                            Name     Sex  \\\n",
      "0            1         0       3         Braund, Mr. Owen Harris    male   \n",
      "2            3         1       3          Heikkinen, Miss. Laina  female   \n",
      "4            5         0       3        Allen, Mr. William Henry    male   \n",
      "5            6         0       3                Moran, Mr. James    male   \n",
      "7            8         0       3  Palsson, Master. Gosta Leonard    male   \n",
      "\n",
      "    Age  SibSp  Parch            Ticket     Fare Cabin Embarked    Age Groups  \\\n",
      "0  22.0      1      0         A/5 21171   7.2500   NaN        S         Youth   \n",
      "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  Young Adults   \n",
      "4  35.0      0      0            373450   8.0500   NaN        S  Young Adults   \n",
      "5   NaN      0      0            330877   8.4583   NaN        Q           NaN   \n",
      "7   2.0      3      1            349909  21.0750   NaN        S      Children   \n",
      "\n",
      "  Fare Range  \n",
      "0        Low  \n",
      "2        Low  \n",
      "4        Low  \n",
      "5        Low  \n",
      "7     Medium  \n",
      "Number of rows: 708\n",
      "Number of rows: 891\n"
     ]
    }
   ],
   "source": [
    "## Find rows with all NA values\n",
    "## isna() - returns a boolean DataFrame that indicates whether each element is NA\n",
    "## any(axis=1) - reduces columns of the boolean DataFrame to only a boolean Series\n",
    "print(df.isna())\n",
    "print(df.isna().any(axis=1))\n",
    "df_nan = df[df.isna().any(axis=1)]\n",
    "print(df_nan.head())\n",
    "print(f\"Number of rows: {df_nan.shape[0]}\")\n",
    "\n",
    "## Drop rows with all NA values\n",
    "df.dropna(how='all', inplace=True)\n",
    "# print(df.head())\n",
    "print(f\"Number of rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After attempting to drop rows with all NA values, the number of rows of the DataFrame is still the same as before. Therefore, there is no row with all NA values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we drop rows with any value in the original DataFrame, there will only be 183 rows left for analysis, which is not representative. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 183\n"
     ]
    }
   ],
   "source": [
    "## Drop rows with any NA values\n",
    "df = df.dropna(how='any', inplace=False)\n",
    "# print(df.head())\n",
    "print(f\"Number of rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some of the attributes do not matter in our survival rate analysis, we will create a new DataFrame selecting only those attributes that are potential factors in our analysis. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass     Sex   Age     Fare Embarked          Age Groups  \\\n",
      "1           1       1  female  38.0  71.2833        C        Young Adults   \n",
      "3           1       1  female  35.0  53.1000        S        Young Adults   \n",
      "6           0       1    male  54.0  51.8625        S  Middle-aged Adults   \n",
      "10          1       3  female   4.0  16.7000        S            Children   \n",
      "11          1       1  female  58.0  26.5500        S  Middle-aged Adults   \n",
      "..        ...     ...     ...   ...      ...      ...                 ...   \n",
      "871         1       1  female  47.0  52.5542        S  Middle-aged Adults   \n",
      "872         0       1    male  33.0   5.0000        S        Young Adults   \n",
      "879         1       1  female  56.0  83.1583        C  Middle-aged Adults   \n",
      "887         1       1  female  19.0  30.0000        S               Youth   \n",
      "889         1       1    male  26.0  30.0000        C        Young Adults   \n",
      "\n",
      "    Fare Range  \n",
      "1         High  \n",
      "3         High  \n",
      "6         High  \n",
      "10      Medium  \n",
      "11        High  \n",
      "..         ...  \n",
      "871       High  \n",
      "872        Low  \n",
      "879       High  \n",
      "887       High  \n",
      "889       High  \n",
      "\n",
      "[183 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_factors = df[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Age Groups', 'Fare Range']]\n",
    "print(df_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the new DataFrame, we have much more data to do the analysis. We only need to drop those rows with NA values in one of those columns that will potentially affect our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 183\n"
     ]
    }
   ],
   "source": [
    "## Drop rows with all NA values\n",
    "df_factors = df_factors.dropna(how='any', inplace=False)\n",
    "# print(df.head())\n",
    "print(f\"Number of rows: {df_factors.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will perform the same analysis with the new DataFrame as above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Ticket Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    158\n",
      "2     15\n",
      "3     10\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_factors.groupby(\"Pclass\")[\"Survived\"].count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower class, 3rd class ticket holders, was the most likely to survive the Titanic disaster. It is almost more than double of the next group most likely to survive - 1st class. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the upper class is the most likely to survive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "female    88\n",
      "male      95\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_factors.groupby(\"Sex\")[\"Survived\"].count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Male passengers are more likely to survive the disaster, almost twice as much as female passengers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before removing those NA values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest passenger: 80.0 years old\n",
      "Youngest passenger: 0.92 years old\n"
     ]
    }
   ],
   "source": [
    "print(\"Oldest passenger:\", df_factors[\"Age\"].max(), \"years old\")\n",
    "print(\"Youngest passenger:\", df_factors[\"Age\"].min(), \"years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age Groups\n",
       "Children              13\n",
       "Youth                 39\n",
       "Young Adults          67\n",
       "Middle-aged Adults    61\n",
       "Seniors                3\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sort age values to groups of age ranges\n",
    "bins = [0, 15, 25, 41, 65, 100]\n",
    "group_names = [\"Children\", \"Youth\", \"Young Adults\", \"Middle-aged Adults\", \"Seniors\"]\n",
    "df_factors['Age Groups'] = pd.cut(df_factors[\"Age\"], bins, labels=group_names)\n",
    "# print(df[[\"Age Groups\", \"Survived\"]])\n",
    "df_factors.groupby(\"Age Groups\")[\"Survived\"].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Young adults are most likely to survive, followed by youth, but seniors are the least likely to survive. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Young adults are still the most likely to survive but this time, middle-aged adults are the second group with the highest survival rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most expensive fare: $512.3292\n",
      "Least expensive fare: $0.0\n"
     ]
    }
   ],
   "source": [
    "fare_lowest = df_factors[\"Fare\"].max()\n",
    "print(f\"Most expensive fare: ${fare_lowest}\")\n",
    "fare_highest = df_factors[\"Fare\"].min()\n",
    "print(f\"Least expensive fare: ${fare_highest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High      154\n",
      "Medium     22\n",
      "Low         7\n",
      "Name: Fare Range, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Discretize variable into equal-sized buckets based on rank or sample quantiles\n",
    "bin_labels_3 = [\"Low\", \"Medium\", \"High\"]\n",
    "q3 = [0, 1/3, 2/3, 1]\n",
    "df_factors[\"Fare Range\"] = pd.qcut(df_factors[\"Fare\"], q=q3, labels=bin_labels_3)\n",
    "# bin_labels_4 = [\"Quartile 1\", \"Quartile 2\", \"Quartile 3\", \"Quartile 4\"]\n",
    "# q4 = [0, 0.25, 0.5, 0.75, 1]\n",
    "# df_factors[\"Fare Range\"] = pd.qcut(df_factors[\"Fare\"], q=q4, labels=bin_labels_4)\n",
    "# bin_labels_6 = [\"Low Low\", \"Low High\", \"Medium Low\", \"Medium High\", \"High Low\", \"High High\"]\n",
    "# q6 = [0, 1/6, 2/6, .5, 4/6, 5/6, 1]\n",
    "# df_factors[\"Fare Range\"] = pd.qcut(df_factors[\"Fare\"], q=q6, labels=bin_labels_6)\n",
    "print(df[\"Fare Range\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those passengers who bought the lowest-tier tickets were most likely to survive. But the difference between ticket tiers does not seem to be striking in terms of survival rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new result is the opposite of the previous one. Now it shows that those passengers who bought the highest-tier tickets were most likely to survive. Perhaps they had the priority to board rescue boats."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n",
      "C     65\n",
      "Q      2\n",
      "S    116\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_factors.groupby(\"Embarked\")[\"Survived\"].count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passengers who embarked at Southampton were significantly more likely to survive the disaster but those at Queenstown had the lowest chance of survival. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new result is similar to the previous one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2011e8f1b66e4ca782a16183c079a9a8ceaa771eb94b3143f514bb5560527e59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
